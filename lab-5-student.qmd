---
title: "Lab 5: Student Evaluations of Teaching"
author: "Tyler Busby"
date: "3/24/25"
format: html
editor: source
---

In this lab, we will be using the `dplyr` package to explore student evaluations
of teaching data. 

**You are expected to use functions from `dplyr` to do your data manipulation!**

# Part 1: GitHub Workflow

Now that you have the Lab 5 repository cloned, you need to make sure you can 
successfully push to GitHub. To do this you need to:

-   Open the `lab-5-student.qmd` file (in the lower right hand corner). 
-   Change the `author` line at the top of the document (in the YAML) to your
name. 
-   Save your file either by clicking on the blue floppy disk or with a shortcut
(command / control + s). 
-   Click the "Git" tab in upper right pane
-   Check the "Staged" box for the `lab-5-student.qmd` file (the file you
changed)
-   Click "Commit"
-   In the box that opens, type a message in "Commit message", such as
"Added my name".
-   Click "Commit".
-   Click the green "Push" button to send your local changes to GitHub.

RStudio will display something like:

```         
>>> /usr/bin/git push origin HEAD:refs/heads/main
To https://github.com/atheobold/introduction-to-quarto-allison-theobold.git
   3a2171f..6d58539  HEAD -> main
```

Now you are ready to go! Remember, as you are going through the lab I would 
strongly recommend rendering your HTML and committing your after **every** 
question! 


# Part 2: Some Words of Advice

Part of learning to program is learning from a variety of resources. Thus, I
expect you will use resources that you find on the internet. There is, however,
an important balance between copying someone else's code and *using their code to learn*.  

Therefore, if you use external resources, I want to know about it.

-   If you used Google, you are expected to "inform" me of any resources you
used by **pasting the link to the resource in a code comment next to where you used that resource**.

-   If you used ChatGPT, you are expected to "inform" me of the assistance you
received by (1) indicating somewhere in the problem that you used ChatGPT 
(e.g., below the question prompt or as a code comment), and (2) downloading and
including the `.txt` file containing your **entire** conversation with ChatGPT.

Additionally, you are permitted and encouraged to work with your peers as you
complete lab assignments, but **you are expected to do your own work**. Copying
from each other is cheating, and letting people copy from you is also cheating.
Please don't do either of those things.

## Setting Up Your Code Chunks

-   The first chunk of this Quarto document should be used to *declare your libraries* (probably only `tidyverse` for now).

-   The second chunk of your Quarto document should be to *load in your data*.

## Save Regularly, Render Often

-   Be sure to **save** your work regularly.
-   Be sure to **render** your file every so often, to check for errors and make
sure it looks nice.
    -   Make sure your Quarto document does not contain `View(dataset)` or `install.packages("package")`, both of these will prevent rendering.
    -   Check your Quarto document for occasions when you looked at the data by
    typing the name of the data frame. Leaving these in means the whole dataset
    will print out and this looks unprofessional. **Remove these!**
    -   If all else fails, you can set your execution options to `error: true`,
    which will allow the file to render even if errors are present.

# Part 3: Let's Start Working with the Data!

## The Data

The `teacher_evals` dataset contains student evaluations of reaching (SET)
collected from students at a University in Poland. There are SET surveys from 
students in all fields and all levels of study offered by the university.

The SET questionnaire that every student at this university completes is as
follows:

> Evaluation survey of the teaching staff of University of Poland. Please
> complete the following evaluation form, which aims to assess the lecturer’s
> performance. Only one answer should be indicated for each question. The
> answers are coded in the following way: 5 - I strongly agree; 4 - I agree;
> 3 - Neutral; 2 - I don’t agree; 1 - I strongly don’t agree.
>
> Question 1: I learned a lot during the course.
>
> Question 2: I think that the knowledge acquired during the course is very
> useful.
>
> Question 3: The professor used activities to make the class more engaging.
>
> Question 4: If it was possible, I would enroll for a course conducted by this
> lecturer again.
>
> Question 5: The classes started on time.
>
> Question 6: The lecturer always used time efficiently.
>
> Question 7: The lecturer delivered the class content in an understandable and
> efficient way.
>
> Question 8: The lecturer was available when we had doubts.
>
> Question 9. The lecturer treated all students equally regardless of their
> race, background and ethnicity.

These data are from the end of the winter semester of the 2020-2021 academic
year. In the period of data collection, all university classes were entirely
online amid the COVID-19 pandemic. While expected learning outcomes were not
changed, the online mode of study could have affected grading policies and could
have implications for data.

**Average SET scores** were combined with many other variables, including:

1.  **characteristics of the teacher** (degree, seniority, gender, SET scores in
the past 6 semesters).
2.  **characteristics of the course** (time of day, day of the week, course
type, course breadth, class duration, class size).
3.  **percentage of students providing SET feedback.**
4.  **course grades** (mean, standard deviation, percentage failed for the
current course and previous 6 semesters).

This rich dataset allows us to **investigate many of the biases in student evaluations of teaching** that have been reported in the literature and to formulate new
hypotheses.

Before tackling the problems below, study the description of each variable
included in the `teacher_evals_codebook.pdf`.

**1. Load the appropriate R packages for your analysis.**

```{r}
#| label: setup
library(tidyverse) #load tidyverse package
library(mosaic) #loads mosaic package
```

**2. Load in the `teacher_evals` data.** 

```{r}
#| label: load-data
teacher_evals <- read_csv("data-raw/teacher_evals.csv")
```

### Data Inspection + Summary

**3. Provide a brief overview (~4 sentences) of the dataset.**

```{r}
#| label: explore-data
head(teacher_evals) #shows first 5 lines of the dataset
nrow(teacher_evals) #shows number of rows in the dataset
summary(teacher_evals) #gives summary of the dataset

```

> "teacher_evals" is a dataset comprised of 22 columns of variables and 8015 rows of cases. The variables include the characteristics of the teacher (teacher_id, seniority, and gender), characteristics of the course (time_of_day, weekday, and class_duration), response share (no_participants and resp_share), course grade information (stud_grade_avg, stud_grade_std, stud_grade_var_coef, percent_failed, stud_grade_avg_cur, stud_grade_std_cur, stud_grade_var_coef_cur, and percent_failed_cur), and SET score information (question_no, SET_score_avg, SET_score_1sem, and maximum_score). Most variables are numeric doubles, with the exception of course_id, weekday, time_of_day, academic_degree, gender, and teacher_id, which is wrongly classified as a double by R. There are a number of NA values in the dataset: 34 in no_participants and resp_share; 41 in stud_grade_avg, stud_grade_std, stud_grade_var_coef, percent_failed, stud_grade_avg_cur, stud_grade_std_cur, stud_grade_var_coef_cur, and percent_failed_cur; 914 in class_duration; and 697 for SET_score_1sem.  

**4. What is the unit of observation (i.e. a single row in the dataset) identified by?**

```{r}
#| label: row-identification
head(teacher_evals) |>
  arrange(teacher_id) #shows first 5 lines of the dataset arranged by teacher_id
```

> The dataset is organized by question per teacher_id, so one row responds to one question for a given teacher.  

**5. Use _one_ `dplyr` pipeline to clean the data by:**

- **renaming the `gender` variable `sex`**
- **removing all courses with fewer than 10 respondents**
- **changing data types in whichever way you see fit (e.g., is the instructor ID really a numeric data type?)**
- **only keeping the columns we will use -- `course_id`, `teacher_id`, `question_no`, `no_participants`, `resp_share`, `SET_score_avg`, `percent_failed_cur`, `academic_degree`, `seniority`, and `sex`**

**Assign your cleaned data to a new variable named `teacher_evals_clean` –- use these data going forward. Save the data as `teacher_evals_clean.csv` in the `data-clean` folder.**

```{r}
#| label: data-cleaning
teacher_evals_clean <- teacher_evals |> #save new data as "teacher_evals_clean"
  rename("sex" = gender) |> #rename gender variable to sex
  filter(no_participants >= 10) |> #removing courses with <10 respondents
  mutate(teacher_id = as.character(teacher_id)) |> #sets teacher_id as a categorical variable
  select(course_id, teacher_id, question_no, no_participants, resp_share, 
         SET_score_avg, percent_failed_cur, academic_degree, seniority, sex) #select only desired variables

write_csv(teacher_evals_clean, "data-clean/teacher_evals_clean.csv") #save dataset as csv in data-clean folder
```

**6. How many unique instructors and unique courses are present in the cleaned dataset?**

```{r}
#| label: unique-courses
teacher_evals_clean |>
  distinct(teacher_id, course_id) |> #find unique teachers and courses
  count() #count number
```

> There are 1094 unique teacher and course combinations in the dataset.

**7. One teacher-course combination has some missing values, coded as `NA`. Which instructor has these missing values? Which course? What variable are the missing values in?**

```{r}
#| label: uncovering-missing-values
teacher_evals_clean |>
  filter(if_any(.cols = -c(teacher_id, course_id), #filters for every column except teacher_id and course_id
                .fns = is.na)) #finds any na values
```

> It appears the teacher-course combination with na values is the the combination of teacher 56347 and course PAB3SE004PA. The value missing is percent_failed_cur.  

**8. What are the demographics of the instructors in this study? Investigate the variables `academic_degree`, `seniority`, and `sex` and summarize your findings in ~3 complete sentences.**

```{r}
#| label: exploring-demographics-of-instructors
teacher_evals_clean |>
  count(academic_degree) |> #find counts teachers with each type of academic degree
  mutate(prop = n/nrow(teacher_evals_clean)) #determines proportion of teachers with that degree type

teacher_evals_clean |>
  count(seniority) |> #counts teachers by years of seniority
  mutate(prop = n/nrow(teacher_evals_clean)) |> #determines proportion of teachers by seniority
  arrange(desc(prop)) #arrange by proportion with largest being at top

teacher_evals_clean |>
  count(sex) |> #find counts teachers by each sex
  mutate(prop = n/nrow(teacher_evals_clean)) #determines proportion of teachers by sex
```

> In the dataset, a majority of the teachers listed are doctors, with 64.06% having a doctorate, 27.18% having a masters, 6.85% having no degrees, and 1.92% having a professional degree. Seniority showed that the largest percentage of teachers have 2 years of seniority with 25.26%, then 6 years, 8 years, 11 years, 4 years, 1 year, 7 years, 10 years, 3 years, 9 years, and 5 years being the smallest with a percentage of 4.11%. Finally, a the highest percentage of teachers were shown to be male, with a slim majority of 51.91%.  

**9. Each course seems to have used a different subset of the nine evaluation questions. How many teacher-course combinations asked all nine questions?**

```{r}
#| label: teacher-course-asked-every-question
teacher_evals_clean |>
  group_by(teacher_id, course_id) |> #groups by teacher and course id
  summarise(questions_answered = count(teacher_id, course_id)) |> #determines number of questions answered by counting number of times each teacher-course combination appears (denoting a new question)
  filter(questions_answered == 9) |> #selects only teachers who asked all 9 questions
  ungroup() |> #ungroups data to allow count function
  count() #counts number of unique teacher-course combinations
```

> Only 49 teacher-course combinations asked all 49 questions.  

## Rate my Professor

**10. Which instructors had the highest and lowest average rating for Question 1 (I learnt a lot during the course.) across all their courses?**

```{r}
#| label: question-1-high-low
teacher_evals_clean |>
  filter(question_no == 901) |> #filter for only question 1
  group_by(teacher_id) |> #group by teacher
  summarise(mean_SET_score_avg = mean(SET_score_avg)) |> #determine average SET score across all classes
  filter(mean_SET_score_avg == c(1,5)) |> #only select teachers with a mean score of 1 or 5
  arrange(mean_SET_score_avg) #arranges by SET score average
```

> In the dataset, 42 teachers recieved the maximum average rating of 5 for question 1 across all their courses, while only 1, teacher 54201, recieved the lowest average rating of 1 across all their courses.   

**11. Which instructors with one year of experience had the highest and lowest average percentage of students failing in the current semester across all their courses?**

```{r}
#| label: one-year-experience-failing-students
teacher_evals_clean |>
  filter(seniority == 1) |> #filter for only 1st year teachers
  group_by(teacher_id) |> #group by teacher
  summarise(mean_percent_failed_cur = mean(percent_failed_cur)) |> #determine percent failing across all classes
  arrange(mean_percent_failed_cur) #arrange by number of students failing
```

> In the dataset, 6 teachers are tied for the lowest percentage of students failing at 0.00%: teacher 102379, 103092, 106126, 86222, 98650, and 98651. The teacher with the highest percentage of students failing is teacher 106692 with 68.00% of students failing.  

**12. Which female instructors with either a doctorate or professional degree had the highest and lowest average percent of students responding to the evaluation across all their courses?**

```{r}
#| label: female-instructor-student-response
teacher_evals_clean |>
  filter(sex == "female",
         academic_degree == c("dr", "prof")) |>
  group_by(teacher_id) |> #group by teacher
  summarise(mean_resp_share = mean(resp_share)) |> #determine average percent response across all classes
  arrange(desc(mean_resp_share)) |> #arrange by mean percent response with highest at top
  head(5) #look at the top 5

teacher_evals_clean |>
  filter(sex == "female",
         academic_degree == c("dr", "prof")) |>
  group_by(teacher_id) |> #group by teacher
  summarise(mean_resp_share = mean(resp_share)) |> #determine average percent response across all classes
  arrange(mean_resp_share) |> #arrange by mean percent response with lowest at top
  head(5) #look at the top 5
```

> The teacher with the highest percentage of responses across all their classes was teacher 101508 with a 52.17% of their students responding, and the teacher with the lowest percentage of responses across all their classes was teacher 56345 with a 4.56% of their students responding.  
